{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import codecs\n",
    "import math #for computemean\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from string import punctuation\n",
    "from random import shuffle\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec # the word2vec model gensim class\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "\n",
    "#sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#zemberek turkish library, change with your path\n",
    "import jpype\n",
    "from jpype import *\n",
    "if not jpype.isJVMStarted():\n",
    "    jpype.startJVM(getDefaultJVMPath(),\"-Djava.class.path=/Users/asus/Desktop/Sentiment Analysis/zemberek-tum-2.0.jar\", \"-ea\")\n",
    "Tr = jpype.JClass(\"net.zemberek.tr.yapi.TurkiyeTurkcesi\")\n",
    "tr = Tr()\n",
    "Zemberek = jpype.JClass(\"net.zemberek.erisim.Zemberek\")\n",
    "zemberek = Zemberek(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweet count: 756\n",
      "Negative tweet count: 1287\n",
      "Neutral tweet count: 957\n",
      "Total tweet count: 3000\n"
     ]
    }
   ],
   "source": [
    "path1 = \"3000tweet/raw_texts/1\"\n",
    "path2 = \"3000tweet/raw_texts/2\"\n",
    "path3 = \"3000tweet/raw_texts/3\"\n",
    "\n",
    "\n",
    "files1 = [f for f in listdir(path1) if isfile(join(path1, f))]\n",
    "files2 = [f for f in listdir(path2) if isfile(join(path2, f))]\n",
    "files3 = [f for f in listdir(path3) if isfile(join(path3, f))]\n",
    "totalFileCount = len(files1) + len(files2) + len(files3)\n",
    "print(\"Positive tweet count:\",len(files1))\n",
    "print(\"Negative tweet count:\",len(files2))\n",
    "print(\"Neutral tweet count:\",len(files3))\n",
    "print(\"Total tweet count:\",len(files1) + len(files2) + len(files3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Sentiment','SentimentText'],index=range(totalFileCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dun Turkcelle tepkilerimizden sonra bugün Turk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>girmezmiyim.. Turkcell kartim bile var.. Yarin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>tam tünelden gecerken 3g cekiyordu:D türkcell'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>turkcell superonline fiber internet veya ADSL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bence Gnçtrkcll Ark Winterfest 2012'de 1.olur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>turkcell sana kıyak geçiyor :D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Turkcelle bağlan hayata diyorum ;)))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Kimse takmıyo beni yaaaaa, turkcell bana mesaj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Bu Turkcell pusula uygulaması iPhone kullanıcı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>o zaman sorun yok bende turkcell için iyi bir ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                      SentimentText\n",
       "0         1  dun Turkcelle tepkilerimizden sonra bugün Turk...\n",
       "1         1  girmezmiyim.. Turkcell kartim bile var.. Yarin...\n",
       "2         1  tam tünelden gecerken 3g cekiyordu:D türkcell'...\n",
       "3         1  turkcell superonline fiber internet veya ADSL ...\n",
       "4         1  bence Gnçtrkcll Ark Winterfest 2012'de 1.olur ...\n",
       "5         1                     turkcell sana kıyak geçiyor :D\n",
       "6         1               Turkcelle bağlan hayata diyorum ;)))\n",
       "7         1  Kimse takmıyo beni yaaaaa, turkcell bana mesaj...\n",
       "8         1  Bu Turkcell pusula uygulaması iPhone kullanıcı...\n",
       "9         1  o zaman sorun yok bende turkcell için iyi bir ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for idx, file in enumerate(files1):\n",
    "    file = open( path1 + \"/\" + file, \"r\", encoding=\"cp1254\") \n",
    "    sentimentDict = {}\n",
    "    sentimentDict[\"Sentiment\"] = 1\n",
    "    sentimentDict[\"SentimentText\"] =  file.read() \n",
    "    df.iloc[idx] = sentimentDict\n",
    "    \n",
    "for idx, file in enumerate(files2):\n",
    "    file = open( path2 + \"/\" + file, \"r\", encoding=\"cp1254\") \n",
    "    sentimentDict = {}\n",
    "    sentimentDict[\"Sentiment\"] = 2\n",
    "    sentimentDict[\"SentimentText\"] =  file.read() \n",
    "    df.iloc[len(files1) + idx] = sentimentDict\n",
    "    \n",
    "for idx, file in enumerate(files3):\n",
    "    file = open( path3 + \"/\" + file, \"r\", encoding=\"cp1254\") \n",
    "    sentimentDict = {}\n",
    "    sentimentDict[\"Sentiment\"] = 3\n",
    "    sentimentDict[\"SentimentText\"] =  file.read() \n",
    "    df.iloc[len(files1) + len(files2) + idx] = sentimentDict\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 3000/3000 [00:00<00:00, 9652.18it/s] \n",
      "progress-bar: 100%|██████████| 3000/3000 [00:02<00:00, 1099.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(tweet):\n",
    "    try:\n",
    "        tweet = tweet.lower() \n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        tokens = [x for x in tokens if not x.startswith('@')]\n",
    "        tokens = [x for x in tokens if not x.startswith('#')]\n",
    "        tokens = [x for x in tokens if not x.startswith('http')]\n",
    "        tokens = [x for x in tokens if not x.startswith('.')]\n",
    "        tokens = [x for x in tokens if not x.startswith('(')]\n",
    "        tokens = [x for x in tokens if not x.startswith(')')]\n",
    "        tokens = [x for x in tokens if not x == ',']       \n",
    "        tokens = [x for x in tokens if not x == '?']\n",
    "        tokens = [x for x in tokens if not x == '!']\n",
    "        tokens = [x for x in tokens if not x == ':']\n",
    "        tokens = [x for x in tokens if not x == ';']\n",
    "        tokens = [x for x in tokens if not x == '\"']\n",
    "        tokens = [x for x in tokens if not x == \"'\"]\n",
    "        return tokens\n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "        return 'NC'\n",
    "    \n",
    "def tokenizeWithZemberek(tweet):\n",
    "    try:\n",
    "        tweet = tweet.lower() \n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        tokens = [x for x in tokens if not x.startswith('@')]\n",
    "        tokens = [x for x in tokens if not x.startswith('#')]\n",
    "        tokens = [x for x in tokens if not x.startswith('http')]\n",
    "        tokens = [x for x in tokens if not x.startswith('.')]\n",
    "        tokens = [x for x in tokens if not x.startswith('(')]\n",
    "        tokens = [x for x in tokens if not x.startswith(')')]\n",
    "        tokens = [x for x in tokens if not x == ',']       \n",
    "        tokens = [x for x in tokens if not x == '?']\n",
    "        tokens = [x for x in tokens if not x == '!']\n",
    "        tokens = [x for x in tokens if not x == ':']\n",
    "        tokens = [x for x in tokens if not x == ';']\n",
    "        tokens = [x for x in tokens if not x == '\"']\n",
    "        tokens = [x for x in tokens if not x == \"'\"]\n",
    "        zemberekTokens = []\n",
    "        for token in tokens:\n",
    "            if token.strip()>'':\n",
    "                zemberekToken = zemberek.kelimeCozumle(token)\n",
    "                if zemberekToken:\n",
    "                    zemberekTokens.append(zemberekToken[0].kok().icerik())\n",
    "                else:\n",
    "                    zemberekTokens.append(token)\n",
    "            \n",
    "        return zemberekTokens\n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "        return 'NC'\n",
    "\n",
    "    \n",
    "def postprocess(data):\n",
    "    data['tokens'] = data['SentimentText'].progress_map(tokenize)\n",
    "    data['zemberekTokens'] = data['SentimentText'].progress_map(tokenizeWithZemberek)\n",
    "    data = data[data.tokens != 'NC']\n",
    "    data.reset_index(inplace=True)\n",
    "    data.drop('index', inplace=True, axis=1)\n",
    "    return data\n",
    "\n",
    "df = postprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>tokens</th>\n",
       "      <th>zemberekTokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dun Turkcelle tepkilerimizden sonra bugün Turk...</td>\n",
       "      <td>[dun, turkcelle, tepkilerimizden, sonra, bugün...</td>\n",
       "      <td>[dun, turkcelle, tepki, sonra, bugün, turkcell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>girmezmiyim.. Turkcell kartim bile var.. Yarin...</td>\n",
       "      <td>[girmezmiyim, turkcell, kartim, bile, var, yar...</td>\n",
       "      <td>[girmezmiyim, turkcell, kartim, bile, var, yar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>tam tünelden gecerken 3g cekiyordu:D türkcell'...</td>\n",
       "      <td>[tam, tünelden, gecerken, 3g, cekiyordu, :d, t...</td>\n",
       "      <td>[tam, tünel, gecerken, 3g, cekiyordu, :d, türk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>turkcell superonline fiber internet veya ADSL ...</td>\n",
       "      <td>[turkcell, superonline, fiber, internet, veya,...</td>\n",
       "      <td>[turkcell, superonline, fiber, internet, veya,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bence Gnçtrkcll Ark Winterfest 2012'de 1.olur ...</td>\n",
       "      <td>[bence, gnçtrkcll, ark, winterfest, 2012, de, ...</td>\n",
       "      <td>[ben, gnçtrkcll, ark, winterfest, 2012, de, ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>turkcell sana kıyak geçiyor :D</td>\n",
       "      <td>[turkcell, sana, kıyak, geçiyor, :d]</td>\n",
       "      <td>[turkcell, sen, kıyak, geç, :d]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Turkcelle bağlan hayata diyorum ;)))</td>\n",
       "      <td>[turkcelle, bağlan, hayata, diyorum, ;)]</td>\n",
       "      <td>[turkcelle, bağla, hayat, de, ;)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Kimse takmıyo beni yaaaaa, turkcell bana mesaj...</td>\n",
       "      <td>[kimse, takmıyo, beni, yaaaaa, turkcell, bana,...</td>\n",
       "      <td>[kimse, takmıyo, ben, yaaaaa, turkcell, ben, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Bu Turkcell pusula uygulaması iPhone kullanıcı...</td>\n",
       "      <td>[bu, turkcell, pusula, uygulaması, iphone, kul...</td>\n",
       "      <td>[bu, turkcell, pusula, uygula, iphone, kullan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>o zaman sorun yok bende turkcell için iyi bir ...</td>\n",
       "      <td>[o, zaman, sorun, yok, bende, turkcell, için, ...</td>\n",
       "      <td>[o, zaman, sorun, yok, bent, turkcell, için, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                      SentimentText  \\\n",
       "0         1  dun Turkcelle tepkilerimizden sonra bugün Turk...   \n",
       "1         1  girmezmiyim.. Turkcell kartim bile var.. Yarin...   \n",
       "2         1  tam tünelden gecerken 3g cekiyordu:D türkcell'...   \n",
       "3         1  turkcell superonline fiber internet veya ADSL ...   \n",
       "4         1  bence Gnçtrkcll Ark Winterfest 2012'de 1.olur ...   \n",
       "5         1                     turkcell sana kıyak geçiyor :D   \n",
       "6         1               Turkcelle bağlan hayata diyorum ;)))   \n",
       "7         1  Kimse takmıyo beni yaaaaa, turkcell bana mesaj...   \n",
       "8         1  Bu Turkcell pusula uygulaması iPhone kullanıcı...   \n",
       "9         1  o zaman sorun yok bende turkcell için iyi bir ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [dun, turkcelle, tepkilerimizden, sonra, bugün...   \n",
       "1  [girmezmiyim, turkcell, kartim, bile, var, yar...   \n",
       "2  [tam, tünelden, gecerken, 3g, cekiyordu, :d, t...   \n",
       "3  [turkcell, superonline, fiber, internet, veya,...   \n",
       "4  [bence, gnçtrkcll, ark, winterfest, 2012, de, ...   \n",
       "5               [turkcell, sana, kıyak, geçiyor, :d]   \n",
       "6           [turkcelle, bağlan, hayata, diyorum, ;)]   \n",
       "7  [kimse, takmıyo, beni, yaaaaa, turkcell, bana,...   \n",
       "8  [bu, turkcell, pusula, uygulaması, iphone, kul...   \n",
       "9  [o, zaman, sorun, yok, bende, turkcell, için, ...   \n",
       "\n",
       "                                      zemberekTokens  \n",
       "0  [dun, turkcelle, tepki, sonra, bugün, turkcell...  \n",
       "1  [girmezmiyim, turkcell, kartim, bile, var, yar...  \n",
       "2  [tam, tünel, gecerken, 3g, cekiyordu, :d, türk...  \n",
       "3  [turkcell, superonline, fiber, internet, veya,...  \n",
       "4  [ben, gnçtrkcll, ark, winterfest, 2012, de, ol...  \n",
       "5                    [turkcell, sen, kıyak, geç, :d]  \n",
       "6                  [turkcelle, bağla, hayat, de, ;)]  \n",
       "7  [kimse, takmıyo, ben, yaaaaa, turkcell, ben, m...  \n",
       "8  [bu, turkcell, pusula, uygula, iphone, kullan,...  \n",
       "9  [o, zaman, sorun, yok, bent, turkcell, için, i...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helmotz Weighting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)\n",
    "\n",
    "def combination(m,n):\n",
    "    return factorial(m)/(factorial(n)*factorial(m-n))\n",
    "\n",
    "def computeMeaning(wordDictX,wordDictC):\n",
    "    meaningDict = {}\n",
    "    \n",
    "    L = 0\n",
    "    B = 0\n",
    "    \n",
    "    for key, value in wordDictX.items(): # key is word , a word is used how many times \n",
    "        B = B + value\n",
    "    \n",
    "    for key, value in wordDictC.items(): #all corpus\n",
    "        L = L + value\n",
    "\n",
    "    for word, count in wordDictX.items():\n",
    "        if count == 0:\n",
    "            meaningDict[word] = (count-1)*math.log10(L/B)\n",
    "        else:\n",
    "            meaningDict[word] = meaningDict[word] = (-1/count)*(math.log10(combination(wordDictC[word],count)))- ((count-1)*math.log10(L/B))\n",
    "    return meaningDict    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helmotz Weighting Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "helmotzDic = {}\n",
    "helmotzZemberekDic = {}\n",
    "\n",
    "helmotzDocumentDics = []\n",
    "helmotzZemberekDocumentDics = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    dic = {}\n",
    "    zemberekDic = {}\n",
    "    for token in row['tokens']:\n",
    "        if token in dic:\n",
    "            dic[token] = dic[token] + 1\n",
    "        else:\n",
    "            dic[token] = 1\n",
    "            \n",
    "        if token in helmotzDic:\n",
    "            helmotzDic[token] = helmotzDic[token] + 1\n",
    "        else:\n",
    "            helmotzDic[token] = 1\n",
    "            \n",
    "    for token in row['zemberekTokens']:\n",
    "        if token in zemberekDic:\n",
    "            zemberekDic[token] = zemberekDic[token] + 1\n",
    "        else:\n",
    "            zemberekDic[token] = 1\n",
    "            \n",
    "        if token in helmotzZemberekDic:\n",
    "            helmotzZemberekDic[token] = helmotzZemberekDic[token] + 1\n",
    "        else:\n",
    "            helmotzZemberekDic[token] = 1\n",
    "    \n",
    "    helmotzDocumentDics.append(dic)\n",
    "    helmotzZemberekDocumentDics.append(zemberekDic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "helmontzMeanings = []\n",
    "helmontzZemberekMeanings = []\n",
    "\n",
    "for helmotzDocumentDic in helmotzDocumentDics:\n",
    "    helmontzMeanings.append(computeMeaning(helmotzDocumentDic, helmotzDic))\n",
    "\n",
    "for helmotzZemberekDocumentDic in helmotzZemberekDocumentDics:\n",
    "    helmontzZemberekMeanings.append(computeMeaning(helmotzZemberekDocumentDic, helmotzZemberekDic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "helmontzMeaningDataFrame=  pd.DataFrame(helmontzMeanings)\n",
    "helmontzZemberekMeaningDataFrame=  pd.DataFrame(helmontzZemberekMeanings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the average of the values of each word in documents is calculated.\n",
    "helmotzDic = helmontzMeaningDataFrame.mean(axis=0).sort_values().to_dict()\n",
    "helmotzZemberekDic = helmontzZemberekMeaningDataFrame.mean(axis=0).sort_values().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(df.tokens),\n",
    "                                                    np.array(df.Sentiment), test_size=0.2)\n",
    "\n",
    "x_train_zemberek, x_test_zemberek, y_train_zemberek, y_test_zemberek = train_test_split(np.array(df.zemberekTokens),\n",
    "                                                    np.array(df.Sentiment), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n",
      "2400it [00:00, 122784.07it/s]\n",
      "600it [00:00, 133011.75it/s]\n",
      "2400it [00:00, 177314.64it/s]\n",
      "600it [00:00, 62993.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def labelizeTweets(tweets, label_type):\n",
    "    labelized = []\n",
    "    for i,v in tqdm(enumerate(tweets)):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v, [label]))\n",
    "    return labelized\n",
    "\n",
    "x_train = labelizeTweets(x_train, 'TRAIN')\n",
    "x_test = labelizeTweets(x_test, 'TEST')\n",
    "\n",
    "x_train_zemberek = labelizeTweets(x_train_zemberek, 'TRAIN')\n",
    "x_test_zemberek = labelizeTweets(x_test_zemberek, 'TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [00:00<00:00, 1196947.63it/s]\n",
      "100%|██████████| 2400/2400 [00:00<00:00, 794250.40it/s]\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"\n",
      "100%|██████████| 2400/2400 [00:00<00:00, 1197944.73it/s]\n",
      "100%|██████████| 2400/2400 [00:00<00:00, 798851.65it/s]\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  if __name__ == '__main__':\n",
      "100%|██████████| 2400/2400 [00:00<00:00, 957421.50it/s]\n",
      "100%|██████████| 2400/2400 [00:00<00:00, 684086.28it/s]\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "100%|██████████| 2400/2400 [00:00<00:00, 957057.39it/s]\n",
      "100%|██████████| 2400/2400 [00:00<00:00, 1196805.33it/s]\n",
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1790200, 2915000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dims = [50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300]\n",
    "n_dim = 200\n",
    "tweet_w2v = Word2Vec(size=n_dim, min_count=3 ,hs=1, window = 7, iter = 100, sg = 0)\n",
    "tweet_w2v.build_vocab([x.words for x in tqdm(x_train)])\n",
    "tweet_w2v.train([x.words for x in tqdm(x_train)],total_examples=tweet_w2v.corpus_count, epochs=tweet_w2v.iter)\n",
    "\n",
    "tweet_w2v_zemberek = Word2Vec(size=n_dim, min_count=3 ,hs=1, window = 7, iter = 100, sg = 0)\n",
    "tweet_w2v_zemberek.build_vocab([x.words for x in tqdm(x_train_zemberek)])\n",
    "tweet_w2v_zemberek.train([x.words for x in tqdm(x_train_zemberek)],total_examples=tweet_w2v_zemberek.corpus_count, epochs=tweet_w2v_zemberek.iter)\n",
    "\n",
    "\n",
    "\n",
    "tweet_w2v_sg = Word2Vec(size=n_dim, min_count=3 ,hs=1, window = 7, iter = 100, sg =1)\n",
    "tweet_w2v_sg.build_vocab([x.words for x in tqdm(x_train)])\n",
    "tweet_w2v_sg.train([x.words for x in tqdm(x_train)],total_examples=tweet_w2v_sg.corpus_count, epochs=tweet_w2v_sg.iter)\n",
    "\n",
    "tweet_w2v_zemberek_sg = Word2Vec(size=n_dim, min_count=3 ,hs=1, window = 7, iter = 100, sg =1)\n",
    "tweet_w2v_zemberek_sg.build_vocab([x.words for x in tqdm(x_train_zemberek)])\n",
    "tweet_w2v_zemberek_sg.train([x.words for x in tqdm(x_train_zemberek)],total_examples=tweet_w2v_zemberek_sg.corpus_count, epochs=tweet_w2v_zemberek_sg.iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tf-idf matrix ...\n",
      "vocab size : 1480\n",
      "building tf-idf matrix zemberek ...\n",
      "vocab size zemberek : 1369\n",
      "building tf-idf matrix sg...\n",
      "vocab size sg : 1480\n",
      "building tf-idf matrix zemberek sg ...\n",
      "vocab size zemberek sg : 1369\n"
     ]
    }
   ],
   "source": [
    "print('building tf-idf matrix ...')\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=3)\n",
    "matrix = vectorizer.fit_transform([x.words for x in x_train])\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "print('vocab size :', len(tfidf))\n",
    "\n",
    "\n",
    "print('building tf-idf matrix zemberek ...')\n",
    "vectorizer_zemberek = TfidfVectorizer(analyzer=lambda x: x, min_df=3)\n",
    "matrix_zemberek = vectorizer_zemberek.fit_transform([x.words for x in x_train_zemberek])\n",
    "tfidf_zemberek = dict(zip(vectorizer_zemberek.get_feature_names(), vectorizer_zemberek.idf_))\n",
    "print('vocab size zemberek :', len(tfidf_zemberek))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('building tf-idf matrix sg...')\n",
    "vectorizer_sg = TfidfVectorizer(analyzer=lambda x: x, min_df=3)\n",
    "matrix_sg = vectorizer_sg.fit_transform([x.words for x in x_train])\n",
    "tfidf_sg = dict(zip(vectorizer_sg.get_feature_names(), vectorizer_sg.idf_))\n",
    "print('vocab size sg :', len(tfidf_sg))\n",
    "\n",
    "\n",
    "print('building tf-idf matrix zemberek sg ...')\n",
    "vectorizer_zemberek_sg = TfidfVectorizer(analyzer=lambda x: x, min_df=3)\n",
    "matrix_zemberek_sg = vectorizer_zemberek_sg.fit_transform([x.words for x in x_train_zemberek])\n",
    "tfidf_zemberek_sg = dict(zip(vectorizer_zemberek_sg.get_feature_names(), vectorizer_zemberek_sg.idf_))\n",
    "print('vocab size zemberek sg :', len(tfidf_zemberek_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildWordVector(tokens, size, multiplyBy, isZemberek, isSg):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            if multiplyBy == \"tfidf\":\n",
    "                if isZemberek:\n",
    "                    if isSg:\n",
    "                        vec += tweet_w2v_zemberek_sg[word].reshape((1, size)) * tfidf_zemberek_sg[word]\n",
    "                    else:\n",
    "                        vec += tweet_w2v_zemberek[word].reshape((1, size)) * tfidf_zemberek[word]\n",
    "                else:\n",
    "                    if isSg:\n",
    "                        vec += tweet_w2v_sg[word].reshape((1, size)) * tfidf_sg[word]\n",
    "                    else:\n",
    "                        vec += tweet_w2v[word].reshape((1, size)) * tfidf[word]\n",
    "            elif multiplyBy == \"helmotz\":\n",
    "                if isZemberek:\n",
    "                    if isSg:\n",
    "                        vec += tweet_w2v_zemberek_sg[word].reshape((1, size)) * helmotzZemberekDic[word]\n",
    "                    else:\n",
    "                        vec += tweet_w2v_zemberek[word].reshape((1, size)) * helmotzZemberekDic[word]\n",
    "                else:\n",
    "                    if isSg:\n",
    "                        vec += tweet_w2v_sg[word].reshape((1, size)) * helmotzDic[word]\n",
    "                    else:\n",
    "                        vec += tweet_w2v[word].reshape((1, size)) * helmotzDic[word]\n",
    "            else:\n",
    "                if isZemberek:\n",
    "                    if isSg:\n",
    "                        vec += tweet_w2v_zemberek_sg[word].reshape((1, size))\n",
    "                    else:\n",
    "                        vec += tweet_w2v_zemberek[word].reshape((1, size))  \n",
    "                else:\n",
    "                    if isSg:\n",
    "                        vec += tweet_w2v_sg[word].reshape((1, size))\n",
    "                    else:\n",
    "                        vec += tweet_w2v[word].reshape((1, size))\n",
    "       \n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not\n",
    "                         # in the corpus. useful for testing.\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "2400it [00:00, 8752.25it/s]\n",
      "600it [00:00, 6999.53it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "2400it [00:00, 6067.39it/s]\n",
      "600it [00:00, 6918.40it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  app.launch_new_instance()\n",
      "2400it [00:00, 6469.57it/s]\n",
      "600it [00:00, 6201.53it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "2400it [00:00, 5852.65it/s]\n",
      "600it [00:00, 7210.03it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "2400it [00:00, 8595.30it/s]\n",
      "600it [00:00, 8194.99it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "2400it [00:00, 6522.47it/s]\n",
      "600it [00:00, 6612.56it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "2400it [00:00, 7113.66it/s]\n",
      "600it [00:00, 8429.10it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "2400it [00:00, 6495.94it/s]\n",
      "600it [00:00, 7979.40it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "2400it [00:00, 6290.54it/s]\n",
      "600it [00:00, 7721.78it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n",
      "2400it [00:00, 6667.80it/s]\n",
      "600it [00:00, 6686.51it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "2400it [00:00, 8369.82it/s]\n",
      "600it [00:00, 8488.89it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "2400it [00:00, 7659.83it/s]\n",
      "600it [00:00, 6558.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#without weighting\n",
    "train_vecs_w2v = np.concatenate([buildWordVector(z, n_dim, \"none\", False, False) for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "train_vecs_w2v = scale(train_vecs_w2v)\n",
    "\n",
    "test_vecs_w2v = np.concatenate([buildWordVector(z, n_dim, \"none\", False, False) for z in tqdm(map(lambda x: x.words, x_test))])\n",
    "test_vecs_w2v = scale(test_vecs_w2v)\n",
    "\n",
    "\n",
    "#without weighting, with zemberek\n",
    "train_vecs_w2v_zemberek = np.concatenate([buildWordVector(z, n_dim, \"none\", True, False) for z in tqdm(map(lambda x: x.words, x_train_zemberek))])\n",
    "train_vecs_w2v_zemberek = scale(train_vecs_w2v_zemberek)\n",
    "\n",
    "test_vecs_w2v_zemberek = np.concatenate([buildWordVector(z, n_dim, \"none\", True, False) for z in tqdm(map(lambda x: x.words, x_test_zemberek))])\n",
    "test_vecs_w2v_zemberek = scale(test_vecs_w2v_zemberek)\n",
    "\n",
    "\n",
    "\n",
    "#with tfidf\n",
    "train_vecs_w2v_tfidf = np.concatenate([buildWordVector(z, n_dim, \"tfidf\", False, False) for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "train_vecs_w2v_tfidf = scale(train_vecs_w2v_tfidf)\n",
    "\n",
    "test_vecs_w2v_tfidf = np.concatenate([buildWordVector(z, n_dim, \"tfidf\", False, False) for z in tqdm(map(lambda x: x.words, x_test))])\n",
    "test_vecs_w2v_tfidf = scale(test_vecs_w2v_tfidf)\n",
    "\n",
    "\n",
    "#with tfidf and zemberek\n",
    "train_vecs_w2v_zemberek_tfidf = np.concatenate([buildWordVector(z, n_dim, \"tfidf\", True, False) for z in tqdm(map(lambda x: x.words, x_train_zemberek))])\n",
    "train_vecs_w2v_zemberek_tfidf = scale(train_vecs_w2v_zemberek_tfidf)\n",
    "\n",
    "test_vecs_w2v_zemberek_tfidf = np.concatenate([buildWordVector(z, n_dim, \"tfidf\", True, False) for z in tqdm(map(lambda x: x.words, x_test_zemberek))])\n",
    "test_vecs_w2v_zemberek_tfidf = scale(test_vecs_w2v_zemberek_tfidf)\n",
    "\n",
    "\n",
    "\n",
    "#with helmotz\n",
    "train_vecs_w2v_helmotz = np.concatenate([buildWordVector(z, n_dim, \"helmotz\", False, False) for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "train_vecs_w2v_helmotz = scale(train_vecs_w2v_helmotz)\n",
    "\n",
    "test_vecs_w2v_helmotz = np.concatenate([buildWordVector(z, n_dim, \"helmotz\", False, False) for z in tqdm(map(lambda x: x.words, x_test))])\n",
    "test_vecs_w2v_helmotz = scale(test_vecs_w2v_helmotz)\n",
    "\n",
    "\n",
    "#with helmotz and zemberek\n",
    "train_vecs_w2v_zemberek_helmotz = np.concatenate([buildWordVector(z, n_dim, \"helmotz\", True, False) for z in tqdm(map(lambda x: x.words, x_train_zemberek))])\n",
    "train_vecs_w2v_zemberek_helmotz = scale(train_vecs_w2v_zemberek_tfidf)\n",
    "\n",
    "test_vecs_w2v_zemberek_helmotz = np.concatenate([buildWordVector(z, n_dim, \"helmotz\", True, False) for z in tqdm(map(lambda x: x.words, x_test_zemberek))])\n",
    "test_vecs_w2v_zemberek_helmotz = scale(test_vecs_w2v_zemberek_helmotz)\n",
    "\n",
    "\n",
    "\n",
    "#without weighting but with sg\n",
    "train_vecs_w2v_sg = np.concatenate([buildWordVector(z, n_dim, \"none\", False, True) for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "train_vecs_w2v_sg = scale(train_vecs_w2v_sg)\n",
    "\n",
    "test_vecs_w2v_sg = np.concatenate([buildWordVector(z, n_dim, \"none\", False, True) for z in tqdm(map(lambda x: x.words, x_test))])\n",
    "test_vecs_w2v_sg = scale(test_vecs_w2v_sg)\n",
    "\n",
    "\n",
    "#without weighting but with sg and zemberek\n",
    "train_vecs_w2v_zemberek_sg = np.concatenate([buildWordVector(z, n_dim, \"none\", True, True) for z in tqdm(map(lambda x: x.words, x_train_zemberek))])\n",
    "train_vecs_w2v_zemberek_sg = scale(train_vecs_w2v_zemberek_sg)\n",
    "\n",
    "test_vecs_w2v_zemberek_sg = np.concatenate([buildWordVector(z, n_dim, \"none\", True, True) for z in tqdm(map(lambda x: x.words, x_test_zemberek))])\n",
    "test_vecs_w2v_zemberek_sg = scale(test_vecs_w2v_zemberek_sg)\n",
    "\n",
    "\n",
    "\n",
    "#with tfidf and sg\n",
    "train_vecs_w2v_tfidf_sg = np.concatenate([buildWordVector(z, n_dim, \"tfidf\", False, True) for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "train_vecs_w2v_tfidf_sg = scale(train_vecs_w2v_tfidf_sg)\n",
    "\n",
    "test_vecs_w2v_tfidf_sg = np.concatenate([buildWordVector(z, n_dim, \"tfidf\", False, True) for z in tqdm(map(lambda x: x.words, x_test))])\n",
    "test_vecs_w2v_tfidf_sg = scale(test_vecs_w2v_tfidf_sg)\n",
    "\n",
    "\n",
    "#with tfidf,zemberek and sg\n",
    "train_vecs_w2v_zemberek_tfidf_sg = np.concatenate([buildWordVector(z, n_dim, \"tfidf\", True, True) for z in tqdm(map(lambda x: x.words, x_train_zemberek))])\n",
    "train_vecs_w2v_zemberek_tfidf_sg = scale(train_vecs_w2v_zemberek_tfidf_sg)\n",
    "\n",
    "test_vecs_w2v_zemberek_tfidf_sg = np.concatenate([buildWordVector(z, n_dim, \"tfidf\", True, True) for z in tqdm(map(lambda x: x.words, x_test_zemberek))])\n",
    "test_vecs_w2v_zemberek_tfidf_sg = scale(test_vecs_w2v_zemberek_tfidf_sg)\n",
    "\n",
    "\n",
    "#with helmotz and sg\n",
    "train_vecs_w2v_helmotz_sg = np.concatenate([buildWordVector(z, n_dim, \"helmotz\", False, True) for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "train_vecs_w2v_helmotz_sg = scale(train_vecs_w2v_helmotz_sg)\n",
    "\n",
    "test_vecs_w2v_helmotz_sg = np.concatenate([buildWordVector(z, n_dim, \"helmotz\", False, True) for z in tqdm(map(lambda x: x.words, x_test))])\n",
    "test_vecs_w2v_helmotz_sg = scale(test_vecs_w2v_helmotz_sg)\n",
    "\n",
    "\n",
    "#with helmotz, zemberek and sg\n",
    "train_vecs_w2v_zemberek_helmotz_sg = np.concatenate([buildWordVector(z, n_dim, \"helmotz\", True, True) for z in tqdm(map(lambda x: x.words, x_train_zemberek))])\n",
    "train_vecs_w2v_zemberek_helmotz_sg = scale(train_vecs_w2v_zemberek_helmotz_sg)\n",
    "\n",
    "test_vecs_w2v_zemberek_helmotz_sg = np.concatenate([buildWordVector(z, n_dim, \"helmotz\", True, True) for z in tqdm(map(lambda x: x.words, x_test_zemberek))])\n",
    "test_vecs_w2v_zemberek_helmotz_sg = scale(test_vecs_w2v_zemberek_helmotz_sg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 0 ): 0.54\n",
      "NaiveBayes  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 0 ): 0.5066666666666667\n",
      "DecisionTree  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 0 ): 0.42\n",
      "MLP  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 0 ): 0.49666666666666665\n",
      "KNN  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 0 ): 0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 0 ): 0.5383333333333333\n",
      "SVM  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 1 ): 0.5383333333333333\n",
      "NaiveBayes  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 1 ): 0.5116666666666667\n",
      "DecisionTree  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 1 ): 0.37833333333333335\n",
      "MLP  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 1 ): 0.5133333333333333\n",
      "KNN  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 1 ): 0.44333333333333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 0 ) ( sg = 0  ) ( zemberek= 1 ): 0.5466666666666666\n",
      "SVM  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 0 ): 0.5333333333333333\n",
      "NaiveBayes  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 0 ): 0.495\n",
      "DecisionTree  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 0 ): 0.41833333333333333\n",
      "MLP  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 0 ): 0.495\n",
      "KNN  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 0 ): 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 0 ): 0.55\n",
      "SVM  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 1 ): 0.53\n",
      "NaiveBayes  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 1 ): 0.505\n",
      "DecisionTree  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 1 ): 0.4116666666666667\n",
      "MLP  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 1 ): 0.5133333333333333\n",
      "KNN  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 1 ): 0.44166666666666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 1 ) ( sg = 0  ) ( zemberek= 1 ): 0.52\n",
      "SVM  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 0 ): 0.5433333333333333\n",
      "NaiveBayes  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 0 ): 0.4583333333333333\n",
      "DecisionTree  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 0 ): 0.415\n",
      "MLP  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 0 ): 0.5\n",
      "KNN  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 0 ): 0.4766666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 0 ): 0.5116666666666667\n",
      "SVM  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 1 ): 0.29\n",
      "NaiveBayes  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 1 ): 0.315\n",
      "DecisionTree  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 1 ): 0.345\n",
      "MLP  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 1 ): 0.3433333333333333\n",
      "KNN  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 1 ): 0.27666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 2 ) ( sg = 0  ) ( zemberek= 1 ): 0.2733333333333333\n",
      "SVM  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 0 ): 0.545\n",
      "NaiveBayes  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 0 ): 0.52\n",
      "DecisionTree  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 0 ): 0.44\n",
      "MLP  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 0 ): 0.5133333333333333\n",
      "KNN  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 0 ): 0.4816666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 0 ): 0.5366666666666666\n",
      "SVM  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 1 ): 0.5716666666666667\n",
      "NaiveBayes  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 1 ): 0.49833333333333335\n",
      "DecisionTree  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 1 ): 0.42833333333333334\n",
      "MLP  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 1 ): 0.535\n",
      "KNN  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 1 ): 0.5083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 0 ) ( sg = 1  ) ( zemberek= 1 ): 0.5566666666666666\n",
      "SVM  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 0 ): 0.555\n",
      "NaiveBayes  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 0 ): 0.48333333333333334\n",
      "DecisionTree  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 0 ): 0.43833333333333335\n",
      "MLP  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 0 ): 0.53\n",
      "KNN  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 0 ): 0.5033333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 0 ): 0.5416666666666666\n",
      "SVM  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 1 ): 0.555\n",
      "NaiveBayes  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 1 ): 0.47333333333333333\n",
      "DecisionTree  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 1 ): 0.44333333333333336\n",
      "MLP  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 1 ): 0.5183333333333333\n",
      "KNN  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 1 ): 0.5083333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 1 ) ( sg = 1  ) ( zemberek= 1 ): 0.5616666666666666\n",
      "SVM  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 0 ): 0.555\n",
      "NaiveBayes  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 0 ): 0.4816666666666667\n",
      "DecisionTree  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 0 ): 0.4116666666666667\n",
      "MLP  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 0 ): 0.5166666666666667\n",
      "KNN  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 0 ): 0.49666666666666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 0 ): 0.5733333333333334\n",
      "SVM  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 1 ): 0.56\n",
      "NaiveBayes  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 1 ): 0.48333333333333334\n",
      "DecisionTree  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 1 ): 0.42\n",
      "MLP  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 1 ): 0.5416666666666666\n",
      "KNN  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 1 ): 0.4866666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting  (tfidf= 2 ) ( sg = 1  ) ( zemberek= 1 ): 0.545\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\"SVM\", \"NaiveBayes\", \"DecisionTree\", \"MLP\", \"KNN\", \"Voting\"]\n",
    "tfidfs = [0, 1, 2]  #without weighting(0), tfidf(1), helmotz(2)\n",
    "zembereks = [0, 1]\n",
    "sgs = [0,1]\n",
    "\n",
    "for sg in sgs:\n",
    "    for tf in tfidfs:\n",
    "        for zemberek in zembereks:\n",
    "            for classifier in classifiers:\n",
    "                cla = None\n",
    "                if classifier == \"SVM\":\n",
    "                    cla = svm.SVC()\n",
    "                if classifier == \"NaiveBayes\":\n",
    "                    cla = GaussianNB()\n",
    "                if classifier == \"DecisionTree\":\n",
    "                    cla = DecisionTreeClassifier()\n",
    "                if classifier == \"MLP\":\n",
    "                    cla = MLPClassifier()\n",
    "                if classifier == \"KNN\":\n",
    "                    cla = KNeighborsClassifier()\n",
    "                if classifier == \"Voting\":\n",
    "                    cla = VotingClassifier(estimators=[('nb', GaussianNB()), ('svm', svm.LinearSVC()), ('mlp', MLPClassifier()),('knn', KNeighborsClassifier())], voting='hard')\n",
    "                if sg == 0:\n",
    "                    if tf == 0 and zemberek ==0:\n",
    "                        cla.fit(train_vecs_w2v, y_train.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v)\n",
    "                        score = accuracy_score(y_test.astype('int'), y_pred)\n",
    "                    elif tf == 0 and zemberek ==1:\n",
    "                        cla.fit(train_vecs_w2v_zemberek, y_train_zemberek.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_zemberek)\n",
    "                        score = accuracy_score(y_test_zemberek.astype('int'), y_pred)\n",
    "                    elif tf == 1 and zemberek ==0:\n",
    "                        cla.fit(train_vecs_w2v_tfidf, y_train.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_tfidf)\n",
    "                        score = accuracy_score(y_test.astype('int'), y_pred)\n",
    "                    elif tf == 1 and zemberek ==1:\n",
    "                        cla.fit(train_vecs_w2v_zemberek_tfidf, y_train_zemberek.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_zemberek_tfidf)\n",
    "                        score = accuracy_score(y_test_zemberek.astype('int'), y_pred)\n",
    "                    elif tf == 2 and zemberek ==0:\n",
    "                        cla.fit(train_vecs_w2v_helmotz, y_train.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_helmotz)\n",
    "                        score = accuracy_score(y_test.astype('int'), y_pred)\n",
    "                    elif tf == 2 and zemberek ==1:\n",
    "                        cla.fit(train_vecs_w2v_zemberek_helmotz, y_train_zemberek.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_zemberek_helmotz)\n",
    "                        score = accuracy_score(y_test_zemberek.astype('int'), y_pred)\n",
    "                if sg == 1:\n",
    "                    if tf == 0 and zemberek ==0:\n",
    "                        cla.fit(train_vecs_w2v_sg, y_train.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_sg)\n",
    "                        score = accuracy_score(y_test.astype('int'), y_pred)\n",
    "                    elif tf == 0 and zemberek ==1:\n",
    "                        cla.fit(train_vecs_w2v_zemberek_sg, y_train_zemberek.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_zemberek_sg)\n",
    "                        score = accuracy_score(y_test_zemberek.astype('int'), y_pred)\n",
    "                    elif tf == 1 and zemberek ==0:\n",
    "                        cla.fit(train_vecs_w2v_tfidf_sg, y_train.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_tfidf_sg)\n",
    "                        score = accuracy_score(y_test.astype('int'), y_pred)\n",
    "                    elif tf == 1 and zemberek ==1:\n",
    "                        cla.fit(train_vecs_w2v_zemberek_tfidf_sg, y_train_zemberek.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_zemberek_tfidf_sg)\n",
    "                        score = accuracy_score(y_test_zemberek.astype('int'), y_pred)\n",
    "                    elif tf == 2 and zemberek ==0:\n",
    "                        cla.fit(train_vecs_w2v_helmotz_sg, y_train.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_helmotz_sg)\n",
    "                        score = accuracy_score(y_test.astype('int'), y_pred)\n",
    "                    elif tf == 2 and zemberek ==1:\n",
    "                        cla.fit(train_vecs_w2v_zemberek_helmotz_sg, y_train_zemberek.astype('int'))\n",
    "                        y_pred = cla.predict(test_vecs_w2v_zemberek_helmotz_sg)\n",
    "                        score = accuracy_score(y_test_zemberek.astype('int'), y_pred)\n",
    "                print(classifier, \" (tfidf=\", tf, \") ( sg =\", sg, \" ) ( zemberek=\", zemberek  , \"):\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
